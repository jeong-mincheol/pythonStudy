{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a350c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse, urlencode, quote\n",
    "\n",
    "def search_id(title):\n",
    "    host = \"https://www.melon.com/search/total/index.htm?\"\n",
    "    payload = {\n",
    "        'mwkLogType' : ['T'],\n",
    "        'searchGnbYn' : ['Y'],\n",
    "        'kkoSpl' : ['Y']\n",
    "    }\n",
    "    payload['q'] = [title]\n",
    "\n",
    "    url = host + urlencode(payload, doseq=True)\n",
    "\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cfa93305",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = search_id(\"난 알아요\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84cb603a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "def my_request(url, method='get'):\n",
    "    head = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'}\n",
    "    if method == \"get\":\n",
    "        return requests.get(url, headers=head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63eae561",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = my_request(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5231f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<button class=\"btn_icon play\" onclick=\"searchLog(\\'web_tot\\',\\'SONG_SONG\\',\\'SO\\',\\'난 알아요\\',\\'50012\\');melon.play.playSong(\\'26020101\\',50012);\" title=\"재생\" type=\"button\"><span class=\"odd_span\">재생</span></button>'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "bs = BeautifulSoup(r.text)\n",
    "target = str(bs.find(\"div\", class_=\"tb_list d_song_list songTypeOne\").find_all(\"tr\")[1].find(\"button\",\"btn_icon play\" ))\n",
    "\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "681f3853",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "p = re.compile(\"playSong\\(\\'([0-9]+)\\',([0-9]+)\\)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5053ea65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'50012'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.findall(target)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1dd52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_id(title):\n",
    "    host = \"https://www.melon.com/search/total/index.htm?\"\n",
    "    payload = {\n",
    "        'mwkLogType' : ['T'],\n",
    "        'searchGnbYn' : ['Y'],\n",
    "        'kkoSpl' : ['Y']\n",
    "    }\n",
    "    payload['q'] = [title]\n",
    "\n",
    "    url = host + urlencode(payload, doseq=True)\n",
    "    r = my_request(url)\n",
    "    text = BeautifulSoup(r.text).find(\"div\", class_=\"tb_list d_song_list songTypeOne\").find_all(\"tr\")[1].find(\"button\",\"btn_icon play\" )['onclick']\n",
    "\n",
    "    return p.findall(text)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cadc48af",
   "metadata": {},
   "outputs": [],
   "source": [
    "songId = search_id(\"하루 끝\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "984a5c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_lyrics2(songIdValue, path='etc'):\n",
    "\n",
    "    url = f\"https://www.melon.com/song/detail.htm?songId={songIdValue}\"\n",
    "    head = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'}\n",
    "    r = requests.get(url, headers=head)\n",
    "\n",
    "    bs = BeautifulSoup(r.text)\n",
    "    lyrics = BeautifulSoup(str(bs.find(\"div\", id=\"d_video_summary\")).replace(\"<br/>\", \"\\n\")).text\n",
    "\n",
    "    if not os.path.isdir(f\"./lyrics/{path}\" ):\n",
    "        os.mkdir(f\"./lyrics/{path}\")\n",
    "\n",
    "    title = bs.find(\"div\", class_=\"song_name\").text.replace(\"곡명\", \"\").strip()\n",
    "    artist = bs.find(\"div\", class_=\"artist\").text.strip()\n",
    "    \n",
    "    f = open(f\"./lyrics/{path}/{artist}-{title}.txt\", 'w', encoding='utf-8')\n",
    "    f.write(lyrics.strip())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bafa18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_lyrics2(songId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f877072e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "#pathlib.Path(\"./a/b/c\").mkdir(parents=True, exist_ok=True) # 상위폴더가 없으면 폴더까지 만들어준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "188298c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_lyrics2(songIdValue, path='etc'):\n",
    "\n",
    "    url = f\"https://www.melon.com/song/detail.htm?songId={songIdValue}\"\n",
    "    head = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'}\n",
    "    r = requests.get(url, headers=head)\n",
    "\n",
    "    bs = BeautifulSoup(r.text)\n",
    "    lyrics = BeautifulSoup(str(bs.find(\"div\", id=\"d_video_summary\")).replace(\"<br/>\", \"\\n\")).text\n",
    "\n",
    "    # if not os.path.isdir(f\"./lyrics/{path}\" ):\n",
    "    #     os.mkdir(f\"./lyrics/{path}\")\n",
    "\n",
    "    pathlib.Path(f\"./{path}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    title = bs.find(\"div\", class_=\"song_name\").text.replace(\"곡명\", \"\").strip()\n",
    "    artist = bs.find(\"div\", class_=\"artist\").text.strip()\n",
    "    \n",
    "    f = open(f\"./lyrics/{path}/{artist}-{title}.txt\", 'w', encoding='utf-8')\n",
    "    f.write(lyrics.strip())\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a4e181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Playdata\\workspace\\melon.py:30: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 30 of the file c:\\Users\\Playdata\\workspace\\melon.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  text = BeautifulSoup(r.text).find(\"div\", class_=\"tb_list d_song_list songTypeOne\").find_all(\"tr\")[1].find(\"button\",\"btn_icon play\" )['onclick']\n",
      "c:\\Users\\Playdata\\workspace\\melon.py:41: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 41 of the file c:\\Users\\Playdata\\workspace\\melon.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  bs = BeautifulSoup(r.text)\n",
      "c:\\Users\\Playdata\\workspace\\melon.py:42: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 42 of the file c:\\Users\\Playdata\\workspace\\melon.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lyrics = BeautifulSoup(str(bs.find(\"div\", id=\"d_video_summary\")).replace(\"<br/>\", \"\\n\")).text\n"
     ]
    }
   ],
   "source": [
    "# 모듈화 호출\n",
    "from melon import search_id, save_lyrics\n",
    "#import melon # 함수 사용 시 melon.함수명() 으로 입력하여 사용해야함\n",
    "#from melon import * # melon 파일안에 모든 함수 임포트\n",
    "\n",
    "save_lyrics(search_id(\"형\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7721abe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\playdata\\appdata\\local\\miniconda3\\lib\\site-packages (5.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#pip install lxml  beautifulsoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e823c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "졸업 대신 유학… 짐싸는 석박사\n",
      "2025.05.22. 오후 6시55\n",
      "[한국이 싫어서 떠나는 이공계 엘리트] <상> 고급인력이 사라진다\n",
      "\n",
      "\n",
      "\n",
      "게티이미지뱅크\n",
      "서울대 인공지능(AI) 연구원에서 석박사 통합과정을 밟고 있는 김지훈(가명·26)씨는 학교를 그만두고 미국 유학을 갈지 고민 중이다. 3년 가까이 몰두한 연구를 포기하더라도 미국에서 학위를 딴 이후의 삶이 더 나을 것이란 생각이 들어서다. 김씨는 “그동안의 연구원 생활을 온전히 인정받지 못하기 때문에 손해를 보겠지만 빅테크 취업을 할 생각이라면 일단 미국에 나가는 것이 훨씬 유리하다”며 “국내에서도 취업은 어렵지 않겠지만, 글로벌 기업과 처우 차이가 크기 때문에 취업을 고민하는 이공계 학생들이라면 해외로 나가지 않을 이유가 없다”고 말했다.\n",
      "\n",
      "김씨처럼 국내 공학계열 대학원에 입학한 이후 졸업하지 않은 학생이 2000년 이후 가장 많은 것으로 집계됐다. 국민일보가 22일 2000~2024년 교육통계 연보를 분석한 결과, 지난해 공학계열 대학원의 입학생 대비 졸업생 비율은 68%로, 10명 중 3명 이상은 졸업하지 않거나 졸업을 포기한 것으로 나타났다.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "실제 공학계열 대학원 입학생 수는 2000년부터 지난해까지 증가 추세를 보인 반면 졸업생 수는 입학생 수에 비례해 늘지 않고 있다. 지난해 공학계열 대학원 입학생은 2만9999명이었지만 졸업생은 2만444명에 불과했다. 입학생과 졸업생 수 차이(9555명)가 1만명 가까이 벌어진 것은 지난해가 처음이다.\n",
      "\n",
      "1만명에 가까운 이공계 대학원생들이 졸업 외에 어떤 경로를 택했는지는 집계되지 않지만 해외 유학을 떠나는 경우가 대부분인 것으로 추산된다. 지난해 기준 국외에 체류 중인 이공계 대학원생은 9332명이었다. 대학생까지 합하면 전체 이공계열 유학생은 2만9770명이다. 국내 이공계 대학원에 입학하는 학생 수(2만9999명)만큼 이공계 인재들이 해외 유학을 택하고 있는 셈이다.\n",
      "\n",
      "이공계 학생들이 국내 석박사 학위를 포기하고 유학을 택하는 것은 해외, 특히 미국 대학원의 풍부한 지원과 해외 학위 취득 시 국내보다 글로벌 빅테크 취업 기회가 더 많기 때문인 것으로 풀이된다. 김씨는 “일단 첫 취업은 미국에서 해야겠다는 대학원생이 대부분”이라며 “연구 실적만큼 중요한 것이 권위 있는 누군가의 추천을 받는 것인데 미국에서 대학원 생활을 하며 사람들을 알아가는 것이 취업이나 연구에 모두 유리하다”고 말했다. 여기에 생활비를 충당하기도 어려운 박한 연구비와 지도교수 위주로 돌아가는 연구실 문화는 이공계 인재 유출을 가속화시키고 있다. 박기범 과학기술정책연구원(STEPI) 선임연구위원은 “지금의 진학 선호도가 유지될 경우 2050년에는 20개 내외 대학을 제외한 나머지 대학들은 이공계 대학원생을 전혀 확보하지 못할 수 있다”고 말했다.\n"
     ]
    }
   ],
   "source": [
    "# 네이버 뉴스 기사 함수안에 주소를 넣으면 제목, 본문, 뉴스시간 다운로드\n",
    "# 제목-시간.txt\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "#from bs4 import BeautifulSoup as BS (as는 별명을 지어준다 BeautifulSoup 사용 시 BS로 사용가능)\n",
    "import pathlib\n",
    "\n",
    "def naver_news_save(url):\n",
    "    head = {'user-agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/136.0.0.0 Safari/537.36'}\n",
    "    r = requests.get(url, headers=head)\n",
    "    bs = BeautifulSoup(r.text)\n",
    "\n",
    "    news_title = bs.find(\"h2\", id=\"title_area\").get_text()\n",
    "    news_time = bs.find(\"span\", class_=\"media_end_head_info_datestamp_time _ARTICLE_DATE_TIME\").get_text().replace(\":\", \"시\")\n",
    "    news_script = BeautifulSoup(str(bs.find(\"article\", id=\"dic_area\")).replace(\"<br/>\", \"\\n\")).get_text().strip()\n",
    "    # bs.find(\"span\", class_=\"end_photo_org\").decompose() 해당 클래스의 내용 삭제제\n",
    "\n",
    "    print(news_title)\n",
    "    print(news_time)\n",
    "    print(news_script)\n",
    "\n",
    "    pathlib.Path(\"./news\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    f = open(f\"./news/{news_title}-{news_time}.txt\", 'w', encoding='utf-8')\n",
    "    f.write(news_script)\n",
    "    f.close()\n",
    "\n",
    "    # 24 ~ 26 line 아래와같이 변경 가능\n",
    "    with open(f\"./news/{news_title}-{news_time}.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write\n",
    "\n",
    "naver_news_save(\"https://n.news.naver.com/article/newspaper/005/0001778209?date=20250523\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "dc9bda84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10000\n",
      "3307\n"
     ]
    }
   ],
   "source": [
    "a = sum([1,2,3,4])\n",
    "print(a)\n",
    "b = sum(map(lambda x : int(x.replace(\",\",\"\")),['1,000','2,000','3,000','4000']))\n",
    "print(b)\n",
    "\n",
    "def tmp(x):\n",
    "    return int(x.replace(\",\", \"\"))\n",
    "\n",
    "\n",
    "c = sum(map(tmp,['1,000', '2,300', '3', '4']))\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b034782c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f7b30e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "with zipfile.ZipFile(\"./이름_생년_성별_10000.zip\", 'r') as f:\n",
    "    f.extractall(\"./mydata/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4c58654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0741459a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2,779\n"
     ]
    }
   ],
   "source": [
    "with open(\"./mydata/\" + os.listdir(\"./mydata\")[0], \"r\") as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05581e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.move(\"./lyrics/아이유-너의 의미 (Feat. 김창완).txt\", \"./lyrics/lyrics/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "55420ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'┐└│¬╟÷_19850809_2xxxxxx.txt'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"./mydata\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d57cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 남자, 여자 파일 정리리\n",
    "# 2. 남자,여자 평균 금액 구하기 \n",
    "\n",
    "import shutil\n",
    "\n",
    "for x in os.listdir(\"./mydata\"):\n",
    "    if x[-11] == '1' or x[-11] == '3':\n",
    "        if not os.path.isdir(\"./mydata/man\" ):\n",
    "            os.mkdir(\"./mydata/man\")\n",
    "        shutil.move(f\"./mydata/{x}\", \"./mydata/man\")\n",
    "    elif x[-11] == '2' or x[-11] == '4':\n",
    "        if not os.path.isdir(\"./mydata/woman\" ):\n",
    "            os.mkdir(\"./mydata/woman\")\n",
    "        shutil.move(f\"./mydata/{x}\", \"./mydata/woman\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a0722d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "여자 평균이 더큼\n",
      "남자 평균 : 11900177.712397356\n",
      "여자 평균 : 12802368.483323347\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "\n",
    "def tmp(data):\n",
    "    return int(data.replace(\",\", \"\"))\n",
    "\n",
    "man_data_list = []\n",
    "for man_data in os.listdir(\"./mydata/man\"):\n",
    "    with open(\"./mydata/man/\" + man_data, 'r') as f:\n",
    "        man_data_list.append(tmp(f.read()))\n",
    "\n",
    "man_average = statistics.mean(man_data_list)\n",
    "\n",
    "woman_data_list = []\n",
    "for woman_data in os.listdir(\"./mydata/woman\"):\n",
    "    with open(\"./mydata/woman/\" + woman_data, 'r') as f:\n",
    "        woman_data_list.append(tmp(f.read()))\n",
    "\n",
    "woman_average = statistics.mean(woman_data_list)\n",
    "\n",
    "if man_average > woman_average:\n",
    "    print(\"남자 평균이 더큼\")\n",
    "else:\n",
    "    print(\"여자 평균이 더큼\")\n",
    "\n",
    "print(\"남자 평균 : \" + str(man_average))\n",
    "print(\"여자 평균 : \" + str(woman_average))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
